{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL - Extract, Transform, Load\n",
    "# Get data from multiple sources (Databases, files, API, etc.)\n",
    "# Transform the data to be useable - (weather e.x.: T for rain - (trace), near nothing).\n",
    "# Load data - store / save our data, often to a database or a file.\n",
    "\n",
    "# Your company wants you to get relevant data from that endpoint - ensure that data is easily useable.\n",
    "# Make a CSV file with all relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests import get, HTTPError, ConnectionError\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_endpoint = 'https://www.reddit.com/r/machinelearning.json'\n",
    "json_data = None\n",
    "try:\n",
    "    req = get(reddit_endpoint, headers = {\"User-agent\": \"max-etl-pipeline\"})\n",
    "    json_data = req.json()\n",
    "except (HTTPError, ConnectionError) as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"data.json\", \"w\") as outfile:\n",
    "    json.dump(json_data,outfile,indent=4)\n",
    "\n",
    "#   Square brackets for list comprehension and list output\n",
    "d = [child.get('data', {}) for child in json_data.get('data', {}).get('children', [])]\n",
    "#                                                   ^ Point to value of the top-level 'data' key\n",
    "#              ^ get 'data' value from each child                ^ Drill down to contents of list \"children\"\n",
    "#                           ^ Get each element in list \"children\"\n",
    "posts = pd.DataFrame(d)\n",
    "\n",
    "# Max's: \n",
    "# df = json_data[\"data\"][\"children\"]\n",
    "# df = [child[\"data\"] for child in df]\n",
    "\n",
    "posts[\"created_utc\"] = pd.to_datetime(posts[\"created_utc\"], unit='s')\n",
    "# If extraneous spaces: e.g. posts[\"title\"].str.strip()\n",
    "\n",
    "# Harvesting: title, ups, downs, created_utc, num_comments\n",
    "\n",
    "posts_sorted = posts.sort_values(by='created_utc')\n",
    "harvest = posts_sorted[['created_utc', 'title', 'ups', 'upvote_ratio', 'num_comments']]\n",
    "\n",
    "harvest.to_csv('reddit_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
