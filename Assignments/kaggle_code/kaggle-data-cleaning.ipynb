{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll be working with the \"Date\" column from the earthquakes dataframe. Investigate this column now: does it look like it contains dates? What is the dtype of the column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where([date_lengths == 24])[1]\n",
    "print('Indices with corrupted data:', indices)\n",
    "earthquakes.loc[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given all of this information, it's your turn to create a new column \"date_parsed\" in the `earthquakes` dataset that has correctly parsed dates in it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in indices:\n",
    "    earthquakes.loc[index, 'Date'] = pd.to_datetime(earthquakes.loc[index, \"Date\"])\n",
    "    earthquakes.loc[index, 'Date'] = earthquakes.loc[index, 'Date'].strftime('%m/%d/%Y')\n",
    "earthquakes['date_parsed'] = pd.to_datetime(earthquakes['Date'], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the euro symbol: €\n"
     ]
    }
   ],
   "source": [
    "var1 = \"This is the euro symbol: €\"\n",
    "var2 = var1.encode(\"utf-8\", errors=\"replace\")\n",
    "print(var2.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\", 'rb') as rawdata:\n",
    "    result = charset_normalizer.detect(rawdata.read(50000))\n",
    "print(result)\n",
    "\n",
    "police_killings = pd.read_csv(\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\", encoding=\"windows-1250\")\n",
    "police_killings.to_csv(\"PoliceKillingsUS-utf8.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take another look at the \"Country\" column and see if there's any more data cleaning we need to do.\n",
    "\n",
    "It looks like 'usa' and 'usofa' should be the same country.  Correct the \"Country\" column in the dataframe to replace 'usofa' with 'usa'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "professors.loc[professors['Country'] == 'usofa', 'Country'] = 'usa'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
