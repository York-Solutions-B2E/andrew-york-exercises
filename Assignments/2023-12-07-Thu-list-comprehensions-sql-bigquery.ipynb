{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3.0, -5, 2, 6, 1.0, 20]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  - Get all integers out of a list of numbers, e.x. `[1,2.5,100.3,3.0,-1.5,-5]`\n",
    "list1 = [1,2.5,100.3,3.0,-1.5,-5,2,6,1.1,1.0,-9.5,20]\n",
    "# My answer: listInts = [x for x in list1 if type(x) == int]\n",
    "# More right:\n",
    "listInts = [int(x) for x in list1 if round(x) == x]\n",
    "\n",
    "listInts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 13, 23, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 53, 63, 73, 83, 93, 103, 113, 123, 130, 131, 132]\n"
     ]
    }
   ],
   "source": [
    "#  - Find all numbers from 1-1000 that have a `3` in them. [integers?]\n",
    "range1 = range(1, 1001, 1)\n",
    "ansList = [x for x in range1 if '3' in str(x)]\n",
    "print(ansList[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#   - Count the number of alphabetic characters in a string (a-z, lower case or upper case)\n",
    "import string\n",
    "string1 = \"abcDEF12.34zxy!!@@\" #9\n",
    "\n",
    "print(sum(1 for x in string1 if x in string.ascii_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 11,\n",
       " 13,\n",
       " 17,\n",
       " 19,\n",
       " 23,\n",
       " 29,\n",
       " 31,\n",
       " 37,\n",
       " 41,\n",
       " 43,\n",
       " 47,\n",
       " 53,\n",
       " 59,\n",
       " 61,\n",
       " 67,\n",
       " 71,\n",
       " 73,\n",
       " 79,\n",
       " 83,\n",
       " 89,\n",
       " 97,\n",
       " 101,\n",
       " 103,\n",
       " 107,\n",
       " 109,\n",
       " 113,\n",
       " 121,\n",
       " 127,\n",
       " 131,\n",
       " 137,\n",
       " 139,\n",
       " 143,\n",
       " 149,\n",
       " 151,\n",
       " 157,\n",
       " 163,\n",
       " 167,\n",
       " 169,\n",
       " 173,\n",
       " 179,\n",
       " 181,\n",
       " 187,\n",
       " 191,\n",
       " 193,\n",
       " 197,\n",
       " 199,\n",
       " 209,\n",
       " 211,\n",
       " 221,\n",
       " 223,\n",
       " 227,\n",
       " 229,\n",
       " 233,\n",
       " 239,\n",
       " 241,\n",
       " 247,\n",
       " 251,\n",
       " 253,\n",
       " 257,\n",
       " 263,\n",
       " 269,\n",
       " 271,\n",
       " 277,\n",
       " 281,\n",
       " 283,\n",
       " 289,\n",
       " 293,\n",
       " 299,\n",
       " 307,\n",
       " 311,\n",
       " 313,\n",
       " 317,\n",
       " 319,\n",
       " 323,\n",
       " 331,\n",
       " 337,\n",
       " 341,\n",
       " 347,\n",
       " 349,\n",
       " 353,\n",
       " 359,\n",
       " 361,\n",
       " 367,\n",
       " 373,\n",
       " 377,\n",
       " 379,\n",
       " 383,\n",
       " 389,\n",
       " 391,\n",
       " 397,\n",
       " 401,\n",
       " 403,\n",
       " 407,\n",
       " 409,\n",
       " 419,\n",
       " 421,\n",
       " 431,\n",
       " 433,\n",
       " 437,\n",
       " 439,\n",
       " 443,\n",
       " 449,\n",
       " 451,\n",
       " 457,\n",
       " 461,\n",
       " 463,\n",
       " 467,\n",
       " 473,\n",
       " 479,\n",
       " 481,\n",
       " 487,\n",
       " 491,\n",
       " 493,\n",
       " 499,\n",
       " 503,\n",
       " 509,\n",
       " 517,\n",
       " 521,\n",
       " 523,\n",
       " 527,\n",
       " 529,\n",
       " 533,\n",
       " 541,\n",
       " 547,\n",
       " 551,\n",
       " 557,\n",
       " 559,\n",
       " 563,\n",
       " 569,\n",
       " 571,\n",
       " 577,\n",
       " 583,\n",
       " 587,\n",
       " 589,\n",
       " 593,\n",
       " 599,\n",
       " 601,\n",
       " 607,\n",
       " 611,\n",
       " 613,\n",
       " 617,\n",
       " 619,\n",
       " 629,\n",
       " 631,\n",
       " 641,\n",
       " 643,\n",
       " 647,\n",
       " 649,\n",
       " 653,\n",
       " 659,\n",
       " 661,\n",
       " 667,\n",
       " 671,\n",
       " 673,\n",
       " 677,\n",
       " 683,\n",
       " 689,\n",
       " 691,\n",
       " 697,\n",
       " 701,\n",
       " 703,\n",
       " 709,\n",
       " 713,\n",
       " 719,\n",
       " 727,\n",
       " 731,\n",
       " 733,\n",
       " 737,\n",
       " 739,\n",
       " 743,\n",
       " 751,\n",
       " 757,\n",
       " 761,\n",
       " 767,\n",
       " 769,\n",
       " 773,\n",
       " 779,\n",
       " 781,\n",
       " 787,\n",
       " 793,\n",
       " 797,\n",
       " 799,\n",
       " 803,\n",
       " 809,\n",
       " 811,\n",
       " 817,\n",
       " 821,\n",
       " 823,\n",
       " 827,\n",
       " 829,\n",
       " 839,\n",
       " 841,\n",
       " 851,\n",
       " 853,\n",
       " 857,\n",
       " 859,\n",
       " 863,\n",
       " 869,\n",
       " 871,\n",
       " 877,\n",
       " 881,\n",
       " 883,\n",
       " 887,\n",
       " 893,\n",
       " 899,\n",
       " 901,\n",
       " 907,\n",
       " 911,\n",
       " 913,\n",
       " 919,\n",
       " 923,\n",
       " 929,\n",
       " 937,\n",
       " 941,\n",
       " 943,\n",
       " 947,\n",
       " 949,\n",
       " 953,\n",
       " 961,\n",
       " 967,\n",
       " 971,\n",
       " 977,\n",
       " 979,\n",
       " 983,\n",
       " 989,\n",
       " 991,\n",
       " 997]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   - [Challenge - requires nesting] - Find all numbers between 1-1000 that are not divisible by any number between 2 and 9. \n",
    "# listWrongs = []\n",
    "# theRange = range(1, 1001)\n",
    "# for i in range(1, 1001):\n",
    "#     for j in range(2, 10):\n",
    "#         if i % j == 0:\n",
    "#             listWrongs.append(i)\n",
    "# ans = [num for num in theRange if num not in listWrongs]\n",
    "\n",
    "# To do the whole thing in 1 (nested) list comprehension:\n",
    "list4 = [x for x in range(1,1001,1) if not True in [True for y in range(2,10,1) if x % y == 0]] \n",
    "# i.e. If it is NOT true that it IS true that x % y = 0 in range of y from 2 to 9, i.e. if x is NOT divisible by y 2-9, append x to list4\n",
    "# list4 = [x for x in range(1,1001,1) if len([y for y in range(2,10,1) if x % y == 0]) == 0] equivalent\n",
    "\n",
    "list4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL/Big Query (Using the noaa historic severe storms dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Find out what state has had the most historic severe storms between 1980 and 1995\n",
    "-- I first tried to do this in SQL with JOIN statements in BigQuery, but this produced error messages I couldn't get around, so I resorted to this:\n",
    "\n",
    "\n",
    "-- One of these for each year\n",
    "SELECT state, COUNT(state) as total_storms\n",
    "FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1995`\n",
    "GROUP BY state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Te has the most storms over the time period, with 24336.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "stormCount = {}\n",
    "data_files = [\n",
    "    'noaa_data/noaa1980.csv', \n",
    "    'noaa_data/noaa1981.csv',\n",
    "    'noaa_data/noaa1982.csv',\n",
    "    'noaa_data/noaa1983.csv',\n",
    "    'noaa_data/noaa1984.csv',\n",
    "    'noaa_data/noaa1985.csv',\n",
    "    'noaa_data/noaa1986.csv',\n",
    "    'noaa_data/noaa1987.csv',\n",
    "    'noaa_data/noaa1988.csv',\n",
    "    'noaa_data/noaa1989.csv',\n",
    "    'noaa_data/noaa1990.csv',\n",
    "    'noaa_data/noaa1991.csv',\n",
    "    'noaa_data/noaa1992.csv',\n",
    "    'noaa_data/noaa1993.csv',\n",
    "    'noaa_data/noaa1994.csv',\n",
    "    'noaa_data/noaa1995.csv']\n",
    "for file_path in data_files:\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        line_count = 0\n",
    "        for col in reader:\n",
    "            if line_count != 0:\n",
    "                state = col[0]\n",
    "                count = int(col[1])\n",
    "                if state in stormCount:\n",
    "                    stormCount[state] += count\n",
    "                else:\n",
    "                    stormCount[state] = count\n",
    "            line_count += 1\n",
    "\n",
    "most_storms = max(stormCount, key = stormCount.get)\n",
    "print(f\"{most_storms} has the most storms over the time period, with {stormCount[most_storms]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Find the average crop damage for storms in 2011\n",
    "SELECT AVG(damage_crops) \n",
    "FROM `bigquery-public-data.noaa_historic_severe_storms.storms_2011`\n",
    "\n",
    "-- Result: 40133.495685522408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- What was the total number of direct and indirect deaths for storms in 2000? What about the total number of direct or indirect injuries?\n",
    "SELECT SUM(deaths_direct + deaths_indirect)\n",
    "FROM `bigquery-public-data.noaa_historic_severe_storms.storms_2000`\n",
    "\n",
    "-- 521\n",
    "\n",
    "SELECT SUM(deaths_direct + deaths_indirect)\n",
    "FROM `bigquery-public-data.noaa_historic_severe_storms.storms_2000`\n",
    "\n",
    "-- 3658"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Big Query / Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Using the same dataset as above, download a CSV to parse in python of the 1000 worst storms in 2022 by magnitude when the magnitude type is \"MG\" or \"EG\" \n",
    "-- and the magnitude was at least 80\n",
    "SELECT * FROM `bigquery-public-data.noaa_historic_severe_storms.storms_2022` \n",
    "WHERE (magnitude_type = \"MG\" OR magnitude_type = \"EG\") AND magnitude >= 80\n",
    "ORDER BY magnitude DESC\n",
    "LIMIT 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High winds %: 33.03964757709251\n",
      "Thunderstorms %: 66.96035242290749\n"
     ]
    }
   ],
   "source": [
    "#    - What percent of event types were thunderstorms vs high winds?\n",
    "import csv\n",
    "\n",
    "with open('noaa_data/worst_storms_2022.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    row_count = sum(1 for x in reader) - 1\n",
    "    file.seek(0)\n",
    "    high_winds = sum(1 for row in reader if row[4] == 'high wind')\n",
    "    thunderstorm_winds = row_count - high_winds\n",
    "\n",
    "print(\"High winds %:\", high_winds / row_count * 100)\n",
    "print(\"Thunderstorms %:\", thunderstorm_winds / row_count * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ha', 'Ar', 'Il', 'Id', 'Fl'] had the fewest storms at 1\n",
      "['Ca', 'So'] had the most storms at 32\n"
     ]
    }
   ],
   "source": [
    "# What state had the least number of these types of storms?  What state had the most?\n",
    "\n",
    "# Get list of all occurrences' states\n",
    "\n",
    "stateHapsList = []\n",
    "with open('noaa_data/worst_storms_2022.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    line_count = 0\n",
    "    for col in reader:\n",
    "        if line_count != 0:\n",
    "            stateHapsList.append(col[2])\n",
    "        line_count += 1\n",
    "\n",
    "# Make dict of occurrences per state\n",
    "state_counts = {}\n",
    "for element in stateHapsList:\n",
    "    state_counts[element] = state_counts.get(element, 0) + 1\n",
    "\n",
    "# Find least common elements\n",
    "min_count = min(state_counts.values())\n",
    "fewest_storms = [x for x, count in state_counts.items() if count == min_count]\n",
    "\n",
    "max_count = max(state_counts.values())\n",
    "most_storms = [x for x, count in state_counts.items() if count == max_count]\n",
    "\n",
    "print(f\"{fewest_storms} had the fewest storms at {min_count}\")\n",
    "print(f\"{most_storms} had the most storms at {max_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144. 139. 136. 129. 113. 113. 111. 109. 104. 104. 104. 104. 104. 104.\n",
      " 104. 104. 103. 101. 101. 101. 100.  98.  97.  97.  96.  96.  96.  96.\n",
      "  96.  96.  96.  96.  96.  96.  96.  96.  96.  96.  96.  95.  95.  95.\n",
      "  95.  95.  94.  94.  93.  93.  92.  91.  91.  91.  91.  91.  91.  90.\n",
      "  90.  90.  90.  90.  89.  89.  89.  89.  89.  88.  88.  87.  87.  87.\n",
      "  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.\n",
      "  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.\n",
      "  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.  87.\n",
      "  87.  87.  87.  87.  87.  86.  86.  86.  86.  86.  86.  86.  86.  85.\n",
      "  85.  85.  85.  84.  84.  84.  83.  83.  83.  83.  83.  83.  83.  83.\n",
      "  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.\n",
      "  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.\n",
      "  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.  83.\n",
      "  83.  83.  82.  82.  82.  82.  82.  82.  82.  82.  82.  81.  81.  81.\n",
      "  81.  81.  81.  81.  81.  81.  81.  81.  80.  80.  80.  80.  80.  80.\n",
      "  80.  80.  80.  80.  80.  80.  80.  80.  80.  80.  80.  80.  80.  80.\n",
      "  80.  80.  80.]\n",
      "Magnitude mean:  88.26872246696036\n",
      "Magnitude median:  87.0\n",
      "Magnitude standard deviation:  9.464659033193188\n"
     ]
    }
   ],
   "source": [
    "#    -  What was the mean, median, and standard deviation of the magnitude?\n",
    "import numpy as np\n",
    "\n",
    "magnitudes = np.array([])\n",
    "with open('noaa_data/worst_storms_2022.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    line_count = 0\n",
    "    for col in reader:\n",
    "        if line_count != 0:\n",
    "            magnitudes = np.append(magnitudes, float(col[19]))\n",
    "        line_count += 1\n",
    "\n",
    "print(magnitudes)\n",
    "print(\"Magnitude mean: \", np.mean(magnitudes))\n",
    "print(\"Magnitude median: \", np.median(magnitudes))\n",
    "print(\"Magnitude standard deviation: \", np.std(magnitudes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
