{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the below Classifiers, do the following:\n",
    "\n",
    "1. Evaluate its performance on the sample 'wine' dataset built into scikit-learn\n",
    "2. Learn and explain how the model works, and if it is binary / multi classification.\n",
    "3. Attempt to explain why the model performed how it did with the given dataset.\n",
    "\n",
    "* Logistic Regression\n",
    "* Decision Trees\n",
    "* Random Forest\n",
    "* Support Vector Machines (SVM) (Both with linear kernels and non-linear kernels!)\n",
    "* Naive Bayes\n",
    "* K-Nearest Neighbors (KNN)\n",
    "* Gradient Boosting Machines (GBM)\n",
    "* Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline   target  \n",
       "0                          3.92   1065.0  class_0  \n",
       "1                          3.40   1050.0  class_0  \n",
       "2                          3.17   1185.0  class_0  \n",
       "3                          3.45   1480.0  class_0  \n",
       "4                          2.93    735.0  class_0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "df = pd.DataFrame(wine.data, columns = wine.feature_names)\n",
    "df['target'] = pd.Categorical.from_codes(wine.target,wine.target_names)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=16)\n",
    "# print(wine.DESCR)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Models probabilities using a logistic function. Works with binary or multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96296\n",
      "0.96497\n",
      "0.96296\n",
      "[[17  0  0]\n",
      " [ 1 17  1]\n",
      " [ 0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=4000)\n",
    "log_model.fit(X_train,y_train)\n",
    "log_pred = log_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, log_pred)\n",
    "precision = precision_score(y_test, log_pred, average='weighted')\n",
    "recall = recall_score(y_test, log_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test,log_pred)\n",
    "\n",
    "print(round(accuracy, 5))\n",
    "print(round(precision, 5))\n",
    "print(round(recall, 5))\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "Method finds splits (decision nodes) that result in information gain (show something about where different class data lie) \\\n",
    "and repeats until most or all data is sorted into pure final (leaf) nodes \\\n",
    "New data is classed according to decision node conditions and majority vote if applicable \\\n",
    "Binary or multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94444\n",
      "0.94444\n",
      "0.94444\n",
      "[[17  0  0]\n",
      " [ 1 17  1]\n",
      " [ 0  1 17]]\n"
     ]
    }
   ],
   "source": [
    "dtree_model = DecisionTreeClassifier()\n",
    "dtree_model.fit(X_train,y_train)\n",
    "dtree_pred = dtree_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, dtree_pred)\n",
    "precision = precision_score(y_test, dtree_pred, average='weighted')\n",
    "recall = recall_score(y_test, dtree_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test,dtree_pred)\n",
    "\n",
    "print(round(accuracy, 5))\n",
    "print(round(precision, 5))\n",
    "print(round(recall, 5))\n",
    "print(confusion)\n",
    "# tree.plot_tree(dtree_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Ensemble of decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98148\n",
      "0.98246\n",
      "0.98148\n",
      "[[17  0  0]\n",
      " [ 0 18  1]\n",
      " [ 0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train,y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, rf_pred)\n",
    "precision = precision_score(y_test, rf_pred, average='weighted')\n",
    "recall = recall_score(y_test, rf_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test,rf_pred)\n",
    "\n",
    "print(round(accuracy, 5))\n",
    "print(round(precision, 5))\n",
    "print(round(recall, 5))\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9629629629629629\n",
      "0.9649664284167209\n",
      "0.9629629629629629\n",
      "[[17  0  0]\n",
      " [ 1 17  1]\n",
      " [ 0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train,y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, svm_pred)\n",
    "precision = precision_score(y_test, svm_pred, average='weighted')\n",
    "recall = recall_score(y_test, svm_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test,svm_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9074074074074074\n",
      "0.9122685185185185\n",
      "0.9074074074074074\n",
      "[[17  0  0]\n",
      " [ 3 15  1]\n",
      " [ 0  1 17]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svm_model = LinearSVC(max_iter=50000)\n",
    "svm_model.fit(X_train,y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, svm_pred)\n",
    "precision = precision_score(y_test, svm_pred, average='weighted')\n",
    "recall = recall_score(y_test, svm_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test,svm_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6111111111111112\n",
      "0.5847701149425287\n",
      "0.6111111111111112\n",
      "[[15  0  2]\n",
      " [ 1 15  3]\n",
      " [ 1 14  3]]\n"
     ]
    }
   ],
   "source": [
    "svml_model = SVC(kernel='rbf') # Sigmoid and poly even worse than this\n",
    "svml_model.fit(X_train,y_train)\n",
    "svml_pred = svml_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, svml_pred)\n",
    "precision = precision_score(y_test, svml_pred, average='weighted')\n",
    "recall = recall_score(y_test, svml_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test,svml_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Looks at each column and makes probability function associating feature values with a given outcome \\\n",
    "Naive means assuming each column is independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n",
      "0.7789760348583877\n",
      "0.7777777777777778\n",
      "[[15  2  0]\n",
      " [ 1 14  4]\n",
      " [ 1  4 13]]\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train,y_train)\n",
    "nb_pred = nb_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, nb_pred)\n",
    "precision = precision_score(y_test, nb_pred, average='weighted')\n",
    "recall = recall_score(y_test, nb_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test,nb_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6851851851851852\n",
      "0.6691798941798942\n",
      "0.6851851851851852\n",
      "[[17  0  0]\n",
      " [ 1 12  6]\n",
      " [ 2  8  8]]\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train,y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, knn_pred)\n",
    "precision = precision_score(y_test, knn_pred, average='weighted')\n",
    "recall = recall_score(y_test, knn_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test,knn_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9629629629629629\n",
      "0.9639917695473251\n",
      "0.9629629629629629\n",
      "[[17  0  0]\n",
      " [ 1 18  0]\n",
      " [ 0  1 17]]\n"
     ]
    }
   ],
   "source": [
    "gbm_model = GradientBoostingClassifier()\n",
    "gbm_model.fit(X_train,y_train)\n",
    "gbm_pred = gbm_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, gbm_pred)\n",
    "precision = precision_score(y_test, gbm_pred, average='weighted')\n",
    "recall = recall_score(y_test, gbm_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test,gbm_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis\n",
    "\n",
    "Find a linear combination of features that best separate the classes. Focused on maximizing separation of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9814814814814815\n",
      "0.9824561403508772\n",
      "0.9814814814814815\n",
      "[[17  0  0]\n",
      " [ 0 18  1]\n",
      " [ 0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train,y_train)\n",
    "lda_pred = lda_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, lda_pred)\n",
    "precision = precision_score(y_test, lda_pred, average='weighted')\n",
    "recall = recall_score(y_test, lda_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test,lda_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
